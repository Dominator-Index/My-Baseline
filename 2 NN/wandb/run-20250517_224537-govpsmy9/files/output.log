Step 0: Loss = 84.5893325805664
Step 1: Loss = 58.5926628112793
/home/ouyangzl/.conda/envs/Baseline/lib/python3.11/site-packages/torch/autograd/graph.py:824: UserWarning: Using backward() with create_graph=True will create a reference cycle between the parameter and its gradient which can cause a memory leak. We recommend using autograd.grad when creating the graph to avoid this. If you have to use this function, make sure to reset the .grad fields of your parameters to None after use to break the cycle and avoid the leak. (Triggered internally at /pytorch/torch/csrc/autograd/engine.cpp:1273.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Step 2: Loss = 18.87967872619629
Step 3: Loss = 107.09295654296875
Step 4: Loss = 20.756250381469727
Step 5: Loss = 8.836807250976562
Step 6: Loss = 110.08955383300781
Step 7: Loss = 77.0271224975586
Step 8: Loss = 4.4843950271606445
Step 9: Loss = 12.888630867004395
Step 10: Loss = 4.213373184204102
Step 11: Loss = 19.17560577392578
Step 12: Loss = 570.9306030273438
Step 13: Loss = 1755.610595703125
Step 14: Loss = 10760706.0
Step 15: Loss = 2.902401803280712e+17
Step 16: Loss = inf
Step 17: Loss = inf
Step 18: Loss = nan
Step 19: Loss = nan
Step 20: Loss = nan
Step 21: Loss = nan
Step 22: Loss = nan
Step 23: Loss = nan
Step 24: Loss = nan
Step 25: Loss = nan
Traceback (most recent call last):
  File "/home/ouyangzl/BaseLine/2 NN/Top_1_eigenvalue.py", line 151, in <module>
    hessian_eigenvalues = compute_hessian_eigenvalues_pyhessian(
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ouyangzl/BaseLine/2 NN/hessian_utils.py", line 94, in compute_hessian_eigenvalues_pyhessian
    hessian_eigen= hessian_computer.eigenvalues(maxIter=1000, tol=1e-8, top_n=top_k, )
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ouyangzl/.conda/envs/Baseline/lib/python3.11/site-packages/pyhessian/hessian.py", line 135, in eigenvalues
    v = orthnormal(v, eigenvectors)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ouyangzl/.conda/envs/Baseline/lib/python3.11/site-packages/pyhessian/utils.py", line 97, in orthnormal
    return normalization(w)
           ^^^^^^^^^^^^^^^^
  File "/home/ouyangzl/.conda/envs/Baseline/lib/python3.11/site-packages/pyhessian/utils.py", line 54, in normalization
    s = group_product(v, v)
        ^^^^^^^^^^^^^^^^^^^
  File "/home/ouyangzl/.conda/envs/Baseline/lib/python3.11/site-packages/pyhessian/utils.py", line 34, in group_product
    return sum([torch.sum(x * y) for (x, y) in zip(xs, ys)])
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
