import torch
import torch.nn as nn
import numpy as np
import time
import matplotlib.pyplot as plt
import sys
import os

# æ·»åŠ è·¯å¾„ä»¥å¯¼å…¥hessian_utils
from hessian_utils import compute_hessian_eigen, compute_hessian_eigen_pyhessian

# ç®€å•çš„æµ‹è¯•ç½‘ç»œ
class SimpleNetwork(nn.Module):
    def __init__(self):
        super(SimpleNetwork, self).__init__()
        self.fc1 = nn.Linear(4, 8, bias=False)
        self.fc2 = nn.Linear(8, 2, bias=False)
        
        # ç®€å•åˆå§‹åŒ–
        nn.init.normal_(self.fc1.weight, 0, 0.1)
        nn.init.normal_(self.fc2.weight, 0, 0.1)
    
    def forward(self, x):
        x = self.fc1(x)
        x = self.fc2(x)
        return x

def simple_hessian_test():
    """ç®€å•æµ‹è¯•ä¸¤ç§Hessianæ–¹æ³•çš„å·®å¼‚"""
    print("ğŸš€ å¼€å§‹ç®€å•Hessianå¯¹æ¯”æµ‹è¯•")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = SimpleNetwork().to(device)
    data = torch.randn(16, 4).to(device)
    targets = torch.randn(16, 2).to(device)
    criterion = nn.MSELoss()
    
    # åˆ›å»ºDataLoader (pyhessianéœ€è¦)
    dataset = torch.utils.data.TensorDataset(data, targets)
    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16)
    
    print(f"ğŸ“Š æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters())}")
    
    top_k = 5  # åªè®¡ç®—å‰5ä¸ªç‰¹å¾å€¼
    
    # æ–¹æ³•1: compute_hessian_eigen
    print("\nğŸ” æ–¹æ³•1: compute_hessian_eigen")
    try:
        start_time = time.time()
        
        # è®¡ç®—losså¹¶ä¿æŒè®¡ç®—å›¾
        output = model(data)
        loss = criterion(output, targets)
        
        eigenvals_1, eigenvecs_1 = compute_hessian_eigen(loss, model.parameters(), top_k=top_k)
        time_1 = time.time() - start_time
        
        print(f"   âœ… æˆåŠŸ! ç”¨æ—¶: {time_1:.3f}s")
        print(f"   ğŸ“ˆ å‰3ä¸ªç‰¹å¾å€¼: {eigenvals_1[:3]}")
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        eigenvals_1, eigenvecs_1 = None, None
    
    # æ–¹æ³•2: compute_hessian_eigen_pyhessian  
    print("\nğŸ” æ–¹æ³•2: compute_hessian_eigen_pyhessian")
    try:
        start_time = time.time()
        
        eigenvals_2, eigenvecs_2 = compute_hessian_eigen_pyhessian(
            model, criterion, data_loader, top_k=top_k, device=device
        )
        time_2 = time.time() - start_time
        
        print(f"   âœ… æˆåŠŸ! ç”¨æ—¶: {time_2:.3f}s")
        print(f"   ğŸ“ˆ å‰3ä¸ªç‰¹å¾å€¼: {eigenvals_2[:3]}")
        
    except Exception as e:
        print(f"   âŒ å¤±è´¥: {e}")
        eigenvals_2, eigenvecs_2 = None, None
    
    # æ¯”è¾ƒç»“æœ
    if eigenvals_1 is not None and eigenvals_2 is not None:
        print(f"\nğŸ“Š ç»“æœæ¯”è¾ƒ:")
        print(f"   â±ï¸ é€Ÿåº¦: æ–¹æ³•1={time_1:.3f}s, æ–¹æ³•2={time_2:.3f}s")
        
        # æ¯”è¾ƒç‰¹å¾å€¼
        diff = np.abs(eigenvals_1[:top_k] - eigenvals_2[:top_k])
        max_diff = np.max(diff)
        print(f"   ğŸ“ˆ ç‰¹å¾å€¼æœ€å¤§å·®å¼‚: {max_diff:.2e}")
        
        print(f"   ğŸ” è¯¦ç»†å¯¹æ¯”:")
        for i in range(min(top_k, len(eigenvals_1), len(eigenvals_2))):
            print(f"      Î»{i+1}: {eigenvals_1[i]:.6f} vs {eigenvals_2[i]:.6f} (å·®å¼‚: {diff[i]:.2e})")
        
        # ç®€å•å¯è§†åŒ–
        plt.figure(figsize=(10, 4))
        
        plt.subplot(1, 2, 1)
        indices = range(min(top_k, len(eigenvals_1), len(eigenvals_2)))
        plt.plot(indices, eigenvals_1[:len(indices)], 'bo-', label='Method 1', linewidth=2)
        plt.plot(indices, eigenvals_2[:len(indices)], 'ro--', label='Method 2', linewidth=2)
        plt.xlabel('Eigenvalue Index')
        plt.ylabel('Eigenvalue')
        plt.title('Eigenvalue Comparison')
        plt.legend()
        plt.grid(True)
        
        plt.subplot(1, 2, 2)
        plt.plot(indices, diff[:len(indices)], 'go-', linewidth=2)
        plt.xlabel('Eigenvalue Index')
        plt.ylabel('|Difference|')
        plt.title('Eigenvalue Differences')
        plt.yscale('log')
        plt.grid(True)
        
        plt.tight_layout()
        plt.savefig('simple_hessian_comparison.png', dpi=300, bbox_inches='tight')
        print(f"\nğŸ“ˆ å¯¹æ¯”å›¾å·²ä¿å­˜")
        
    else:
        print(f"\nâŒ æ— æ³•æ¯”è¾ƒç»“æœ")

def training_step_comparison():
    """åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¯”è¾ƒä¸¤ç§æ–¹æ³•"""
    print(f"\nğŸ‹ï¸ è®­ç»ƒè¿‡ç¨‹ä¸­çš„Hessianå¯¹æ¯”")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = SimpleNetwork().to(device)
    data = torch.randn(16, 4).to(device)
    targets = torch.randn(16, 2).to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)
    
    # åˆ›å»ºDataLoader
    dataset = torch.utils.data.TensorDataset(data, targets)
    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16)
    
    top_k = 3
    
    print(f"ğŸ“Š åœ¨å‰3ä¸ªè®­ç»ƒæ­¥éª¤ä¸­æ¯”è¾ƒç‰¹å¾å€¼:")
    
    for step in range(3):
        print(f"\nğŸ“ è®­ç»ƒæ­¥éª¤ {step + 1}:")
        
        # å‰å‘ä¼ æ’­
        output = model(data)
        loss = criterion(output, targets)
        
        print(f"   æŸå¤±: {loss.item():.6f}")
        
        # æ–¹æ³•1
        try:
            eigenvals_1, _ = compute_hessian_eigen(loss, model.parameters(), top_k=top_k)
            print(f"   æ–¹æ³•1ç‰¹å¾å€¼: {eigenvals_1[:top_k]}")
        except Exception as e:
            print(f"   æ–¹æ³•1å¤±è´¥: {e}")
            eigenvals_1 = None
        
        # æ–¹æ³•2
        try:
            eigenvals_2, _ = compute_hessian_eigen_pyhessian(
                model, criterion, data_loader, top_k=top_k, device=device
            )
            print(f"   æ–¹æ³•2ç‰¹å¾å€¼: {eigenvals_2[:top_k]}")
        except Exception as e:
            print(f"   æ–¹æ³•2å¤±è´¥: {e}")
            eigenvals_2 = None
        
        # æ¯”è¾ƒ
        if eigenvals_1 is not None and eigenvals_2 is not None:
            diff = np.abs(eigenvals_1[:top_k] - eigenvals_2[:top_k])
            print(f"   ç‰¹å¾å€¼å·®å¼‚: {diff}")
            print(f"   æœ€å¤§å·®å¼‚: {np.max(diff):.2e}")
        
        # åå‘ä¼ æ’­å’Œä¼˜åŒ–
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

if __name__ == "__main__":
    # è¿è¡Œç®€å•æµ‹è¯•
    simple_hessian_test()
    
    print("\n" + "="*50)
    
    # è¿è¡Œè®­ç»ƒæ­¥éª¤æµ‹è¯•
    training_step_comparison()
    
    print(f"\nğŸ¯ æµ‹è¯•å®Œæˆ!")
    print(f"ğŸ’¡ å¦‚æœPyHessianæ›´æ…¢ï¼Œå¯èƒ½æ˜¯å› ä¸º:")
    print(f"   - ä½¿ç”¨äº†æ›´ç²¾ç¡®ä½†æ…¢çš„Lanczosç®—æ³•")
    print(f"   - åŒ…å«æ›´å¤šæ•°å€¼ç¨³å®šæ€§æ£€æŸ¥")
    print(f"   - é¿å…è®¡ç®—å®Œæ•´HessiançŸ©é˜µï¼Œå†…å­˜æ•ˆç‡æ›´é«˜")